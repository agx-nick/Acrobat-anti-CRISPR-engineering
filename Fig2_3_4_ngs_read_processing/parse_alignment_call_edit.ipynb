{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82738a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in extracted target regions post-alignment and parse to identify edits within \n",
    "# user-defined target windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287cc3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081263a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now read in the aligned samples and:\n",
    "# (1) dict of lists with barcodes identifying groups as the key and list of CIGARs as values\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def read_aligns(input_dir, bc_start, bc_end):\n",
    "    \n",
    "    index_lst = []\n",
    "    \n",
    "    master_dict = defaultdict(dict)\n",
    "    \n",
    "    for subdir, dirs, files in os.walk(input_dir):\n",
    "                \n",
    "        if len(files) != 0:\n",
    "            \n",
    "            for file in tqdm(files):\n",
    "                \n",
    "                if \"needleall\" in file:\n",
    "                    full_path = subdir + \"/\" + file\n",
    "                    #print(full_path)\n",
    "                    \n",
    "                    sample_name = file.split(\".\")[0]\n",
    "                    #print(sample_name)\n",
    "                    \n",
    "                    sample_dict = defaultdict(list)\n",
    "                    \n",
    "                    with open(full_path) as align:\n",
    "                    \n",
    "                        line_1 = align.readline()\n",
    "                        line_2 = align.readline()\n",
    "                        line_3 = align.readline()\n",
    "                    \n",
    "                        for line in tqdm(align):\n",
    "                        \n",
    "                            #print(line)\n",
    "                            line_rstrip = line.rstrip('\\n')\n",
    "                            line_split = line_rstrip.split('\\t')\n",
    "                            read_name = line_split[0]\n",
    "                            cigar = line_split[5]\n",
    "                            read = line_split[9]\n",
    "                            bc = read[bc_start:bc_end]\n",
    "                            sample_dict[bc].append(cigar)\n",
    "                            \n",
    "                        master_dict[sample_name].update(sample_dict)\n",
    "            \n",
    "    print(master_dict)\n",
    "    \n",
    "    return master_dict\n",
    "    \n",
    "in_align = read_aligns(\"user defined in dir\", 7, 14)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fa8d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now loop through master dictionary and calculate on-target edit efficiency\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import statistics\n",
    "\n",
    "def calc_edit(in_dict, cutoff):\n",
    "    \n",
    "    filter_match = r'^(\\d+)[M]{1}(\\d+[MID]{1})+(\\d+)[M]{1}$'\n",
    "    univ_string = r'(\\d+)([MID]{1})'\n",
    "    \n",
    "    out_dict = {} # list of series with samples as keys\n",
    "    \n",
    "    for sample, dct in tqdm(in_dict.items()):\n",
    "        \n",
    "        edit_sries = pd.Series()\n",
    "        tot_read_sries = pd.Series()\n",
    "        \n",
    "        read_rep_lst = []\n",
    "        \n",
    "        for bc, lst in dct.items():\n",
    "            \n",
    "            #print(tam)\n",
    "            \n",
    "            num_reads = len(lst)\n",
    "            read_rep_lst.append(num_reads)\n",
    "            edited_reads = 0\n",
    "            allele_id = []\n",
    "            \n",
    "            if num_reads >= cutoff:\n",
    "                \n",
    "                for cigar in lst:\n",
    "\n",
    "                    parse = re.findall(univ_string, cigar)\n",
    "                    i = 0 # init amplicon at 5' end\n",
    "                    amp_index_lst = []\n",
    "                    j = 0\n",
    "\n",
    "                    for element in parse:\n",
    "\n",
    "                        edit_len = int(element[0])\n",
    "                        edit_type = element[1]\n",
    "\n",
    "                        if edit_type == \"M\" or edit_type == \"D\":\n",
    "\n",
    "                            i += edit_len\n",
    "\n",
    "                            amp_index_lst.append(i)\n",
    "\n",
    "                        if edit_type == \"D\":\n",
    "\n",
    "                            indl_bgin = i - edit_len\n",
    "\n",
    "                            if i in range(29, 34) and edit_len > 0: # indexes depend on amplicon design\n",
    "\n",
    "                                edited_reads += 1\n",
    "                                allele_id.append(cigar)\n",
    "                                \n",
    "                                break\n",
    "\n",
    "                            elif indl_bgin in range(29, 34) and edit_len > 0: # indexes depend on amplicon design\n",
    "\n",
    "                                edited_reads += 1\n",
    "                                allele_id.append(cigar)\n",
    "                                \n",
    "                                break\n",
    "\n",
    "                edit_rate = round(edited_reads / num_reads, 3)\n",
    "                \n",
    "                edit_sries[bc] = edit_rate\n",
    "                tot_read_sries[bc] = num_reads\n",
    "                \n",
    "        med = statistics.median(read_rep_lst)\n",
    "        mean = statistics.mean(read_rep_lst)\n",
    "\n",
    "        out_dict[sample + \"_edit_rate\"] = edit_sries\n",
    "        out_dict[sample + \"_tot_reads\"] = tot_read_sries\n",
    "        \n",
    "    return out_dict\n",
    "                                            \n",
    "calc_1 = calc_edit(in_align, 0)\n",
    "                \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3519455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now loop through master dictionary and calculate on-target edit efficiency\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import statistics\n",
    "import collections\n",
    "from scipy.stats import entropy\n",
    "\n",
    "def calc_entrpy(in_dict, cutoff):\n",
    "    \n",
    "    filter_match = r'^(\\d+)[M]{1}(\\d+[MID]{1})+(\\d+)[M]{1}$'\n",
    "    univ_string = r'(\\d+)([MID]{1})'\n",
    "    \n",
    "    out_dict = {} # list of series with samples as keys\n",
    "    \n",
    "    for sample, dct in tqdm(in_dict.items()):\n",
    "        \n",
    "        edit_sries = pd.Series()\n",
    "        \n",
    "        read_rep_lst = []\n",
    "        \n",
    "        for tam, lst in dct.items():\n",
    "            \n",
    "            #print(tam)\n",
    "            \n",
    "            num_reads = len(lst)\n",
    "            read_rep_lst.append(num_reads)\n",
    "            edited_reads = 0\n",
    "            allele_id = []\n",
    "            \n",
    "            if num_reads >= cutoff:\n",
    "                \n",
    "                for cigar in lst:\n",
    "\n",
    "                    parse = re.findall(univ_string, cigar)\n",
    "                    i = 0 # init amplicon at 5' end\n",
    "                    amp_index_lst = []\n",
    "                    j = 0\n",
    "\n",
    "                    for element in parse:\n",
    "\n",
    "                        edit_len = int(element[0])\n",
    "                        edit_type = element[1]\n",
    "                        \n",
    "                        if edit_type == \"M\" or edit_type == \"D\":\n",
    "                            \n",
    "                            i += edit_len\n",
    "\n",
    "                            amp_index_lst.append(i)\n",
    "\n",
    "                        if edit_type == \"D\":\n",
    "\n",
    "                            indl_bgin = i - edit_len\n",
    "                            #print(indl_bgin)\n",
    "                            #print(i)\n",
    "                            \n",
    "                            if i in range(26, 34):\n",
    "\n",
    "                                edited_reads += 1\n",
    "                                allele_id.append(cigar)\n",
    "                                #print(\"edit detected\")\n",
    "                                \n",
    "                                break\n",
    "\n",
    "                            elif indl_bgin in range(26, 34):\n",
    "                                \n",
    "                                edited_reads += 1\n",
    "                                allele_id.append(cigar)\n",
    "                                #print(\"edit detected\")\n",
    "                                \n",
    "                                break\n",
    "                                \n",
    "                allele_uniq = list(set(allele_id))\n",
    "\n",
    "                #print(allele_uniq)\n",
    "                counter = collections.Counter(allele_uniq)\n",
    "                counter_vals = list(counter.values())\n",
    "                #print(counter_vals)\n",
    "                entrpy = entropy(counter_vals, base = 2)\n",
    "                if tam == \"ATAATAC\":\n",
    "                    \n",
    "                    print(entrpy)\n",
    "                    print(allele_uniq)\n",
    "                #print(entrpy)\n",
    "                \n",
    "                edit_rate = round(edited_reads / num_reads, 3)\n",
    "                \n",
    "                edit_sries[tam] = entrpy\n",
    "                \n",
    "        #print(edit_sries)\n",
    "        print(sample)\n",
    "        med = statistics.median(read_rep_lst)\n",
    "        mean = statistics.mean(read_rep_lst)\n",
    "        print(med)\n",
    "        print(mean)\n",
    "        out_dict[sample] = edit_sries\n",
    "        \n",
    "    return out_dict\n",
    "                            \n",
    "                            \n",
    "#calc_entrpy_1 = calc_entrpy(batch_1, 0)\n",
    "calc_entrpy_10 = calc_entrpy(combined, 10)\n",
    "\n",
    "                \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9098b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "in_df = pd.read_csv(\"/home/ec2-user/ngs_data/MiSeq_PE300_090123/5_outs/2023Sep06_10_read_edit_eff_combined_filterdf.csv\", \n",
    "                   index_col = 0)\n",
    "\n",
    "print(in_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cff1358",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calc_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37a0580",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def analyze_master_df(in_dict, title):\n",
    "    \n",
    "    master_df = pd.DataFrame.from_dict(in_dict)\n",
    "    master_df.to_csv(\"/home/ec2-user/ngs_data/MiSeq_PE400_111923/3_tam_analysis/\" + title)\n",
    "    print(master_df)\n",
    "    \n",
    "    plt.scatter(master_df[\"agx101_23_tot_reads\"], master_df[\"agx101_15_tot_reads\"], alpha = 0.15)\n",
    "    plt.scatter(master_df[\"agx101_23_tot_reads\"], master_df[\"agx101_27_tot_reads\"], alpha = 0.15)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    plt.scatter(master_df[\"agx101_27_edit_rate\"], master_df[\"agx101_15_edit_rate\"], c = master_df[\"agx101_15_tot_reads\"], \n",
    "                alpha = 0.15)\n",
    "    \n",
    "    #plt.scatter(master_df[\"agx101_27_tot_reads\"] - master_df[\"agx101_23_tot_reads\"], master_df[\"agx101_15_edit_rate\"])\n",
    "    \n",
    "#analyze_1 = analyze_master_df(calc_entrpy_1, \"2023Aug24_read_edit_eff_no_filterdf.csv\")\n",
    "#analyze_10 = analyze_master_df(calc_10, \"2023Sep06_10_read_edit_eff_combined_filterdf.csv\")\n",
    "#analyze_100 = analyze_master_df(calc_100, \"2023Aug24_100_read_edit_eff_filterdf.csv\")\n",
    "\n",
    "analyze = analyze_master_df(calc_1, \"2023Nov19_indel_tams_cutoff0.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847c7917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you will want to combine across batches -- confirm sample key with JM and then have a final master df \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
