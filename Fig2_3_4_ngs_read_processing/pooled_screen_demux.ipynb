{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82738a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in merged fqs and parse file to extract target regions for downstream editing quantification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287cc3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0400e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the reference FASTA file\n",
    "ref_fasta = '/home/ec2-user/ngs_data/MiSeq_PE150_20240412/refs/2024Apr13_mismatch_lib.fa'\n",
    "from collections import defaultdict\n",
    "from Bio import SeqIO\n",
    "import gzip\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "import os\n",
    "\n",
    "def read_ref_fasta(file_path):\n",
    "    \"\"\"Read a FASTA file and return a dictionary of sequences.\"\"\"\n",
    "    sequences = defaultdict(list)\n",
    "    for record in SeqIO.parse(file_path, \"fasta\"):\n",
    "        #print(record)\n",
    "        sequences[record.id] = str(record.seq)\n",
    "    #print(sequences)\n",
    "    return sequences\n",
    "\n",
    "read_1 = read_ref_fasta(ref_fasta)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a237153f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through provided in_dir and parse specified fq files and write a split fastq file \n",
    "# based on the error corrected barcode id\n",
    "\n",
    "from Bio import SeqIO\n",
    "import gzip\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "import os\n",
    "import Levenshtein\n",
    "import editdistance\n",
    "\n",
    "def fuzzy_match_id(query_id, ref_ids, max_mismatches=0):\n",
    "    \"\"\"Find a matching ID in ref_ids allowing for a certain number of mismatches.\"\"\"\n",
    "    for ref_id in ref_ids:\n",
    "        if editdistance.eval(query_id, ref_id) <= max_mismatches:\n",
    "            return ref_id\n",
    "    return None\n",
    "\n",
    "def parse_fq(in_dir, grep_str, out_dir):\n",
    "    \n",
    "    for filename in os.listdir(in_dir):\n",
    "        \n",
    "        if filename.endswith(\"extendedFrags.fastq.gz\"): # only consider merged reads\n",
    "        \n",
    "            file_path = os.path.join(in_dir, filename)\n",
    "    \n",
    "            with gzip.open(file_path, \"rt\") as handle:\n",
    "\n",
    "                print(file_path)\n",
    "                \n",
    "                record_lst = []\n",
    "                record_dict = defaultdict(list)\n",
    "                \n",
    "                for record in tqdm(SeqIO.parse(handle, \"fastq\")):\n",
    "\n",
    "                    seq = str(record.seq)\n",
    "                    match = re.search(grep_str, seq)\n",
    "\n",
    "                    if match != None:\n",
    "                        \n",
    "                        tar_region = re.findall(grep_str, seq)[0]\n",
    "                        mm_bc = tar_region[9:17]\n",
    "                        ref_id = fuzzy_match_id(mm_bc, read_1.keys())\n",
    "                        \n",
    "                        if ref_id != None:\n",
    "                            record_dict[ref_id].append(record)\n",
    "                \n",
    "                for ref_id, record_lst in record_dict.items():\n",
    "                \n",
    "                    out_fp = out_dir + \"/\" + filename.split(\".\")[0] + \"_\" + ref_id + \".fastq\"\n",
    "                    \n",
    "                    with open(out_fp, \"w\") as output_handle:\n",
    "                        \n",
    "                        SeqIO.write(record_lst, output_handle, \"fastq\")\n",
    "                    \n",
    "                \n",
    "                        \n",
    "parse_1 = parse_fq(\"provided input files\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081263a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now read in the parsed query fasta and the reference fasta\n",
    "# based on the mismatch-bc, compute the LD and use as a proxy for editing efficiency\n",
    "\n",
    "from Bio import SeqIO\n",
    "import Levenshtein\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "from Bio import SeqIO\n",
    "import Levenshtein\n",
    "import editdistance\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "out_dict = {}\n",
    "\n",
    "def read_fasta(file_path):\n",
    "    \"\"\"Read a FASTA file and return a dictionary of sequences.\"\"\"\n",
    "    sequences = defaultdict(list)\n",
    "    for record in SeqIO.parse(file_path, \"fasta\"):\n",
    "        #print(record)\n",
    "        sequences[record.id].append(str(record.seq))\n",
    "    #print(sequences)\n",
    "    return sequences\n",
    "\n",
    "def fuzzy_match_id(query_id, ref_ids, max_mismatches=2):\n",
    "    \"\"\"Find a matching ID in ref_ids allowing for a certain number of mismatches.\"\"\"\n",
    "    for ref_id in ref_ids:\n",
    "        if editdistance.eval(query_id, ref_id) <= max_mismatches:\n",
    "            return ref_id\n",
    "    return None\n",
    "\n",
    "def calculate_levenshtein(ref_sequences, query_sequences):\n",
    "    \"\"\"Calculate Levenshtein distance between reference and query sequences.\"\"\"\n",
    "    grep_str = r\"CTTATGC[ATCG]+ACCGGT\"\n",
    "    results = defaultdict(list)\n",
    "    for query_id, query_seq_lst in tqdm(query_sequences.items()):\n",
    "        ref_id = fuzzy_match_id(query_id, ref_sequences.keys())\n",
    "        if ref_id:\n",
    "                    \n",
    "            for query_seq in query_seq_lst:\n",
    "\n",
    "                    ref_seq = ref_sequences[ref_id][0]\n",
    "                    tar_ref_seq = re.findall(grep_str, ref_seq)[0][7:-6]\n",
    "                    tar_query_seq = query_seq[24:-6]\n",
    "                    if len(tar_ref_seq) != len(tar_query_seq): # only consider reads with indels\n",
    "                        \n",
    "                        ld = Levenshtein.distance(tar_ref_seq.upper(), tar_query_seq.upper())\n",
    "                        results[ref_id].append(ld)\n",
    "                        \n",
    "                    else:\n",
    "                        \n",
    "                        ld = 0\n",
    "                        results[ref_id].append(ld)\n",
    "    \n",
    "    out_dict[filename] = results\n",
    "\n",
    "# Path to the reference FASTA file\n",
    "ref_fasta = 'ref.fa'\n",
    "# Path to the directory containing query FASTA files\n",
    "query_directory = 'query_dir'\n",
    "\n",
    "# Read the reference sequences\n",
    "ref_sequences = read_fasta(ref_fasta)\n",
    "\n",
    "# Loop through all files in the directory containing query FASTA files\n",
    "for filename in tqdm(os.listdir(query_directory)):\n",
    "    if filename.endswith(\"grep_str\"):  # Ensure processing only FASTA files\n",
    "        file_path = os.path.join(query_directory, filename)\n",
    "        query_sequences = read_fasta(file_path)\n",
    "        levenshtein_distances = calculate_levenshtein(ref_sequences, query_sequences)\n",
    "\n",
    "print(out_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec409100",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ee_dict = {} # dict of series\n",
    "\n",
    "for sample, ld_dict in out_dict.items():\n",
    "    \n",
    "    #print(sample)\n",
    "    sample_sries = pd.Series()\n",
    "    for mm_bc, ld_lst in ld_dict.items():\n",
    "        \n",
    "        edit_eff_proxy = 1 - (ld_lst.count(0) / len(ld_lst))\n",
    "        sample_sries[mm_bc] = edit_eff_proxy\n",
    "        ee_dict[sample] = sample_sries\n",
    "        \n",
    "ee_df = pd.DataFrame(ee_dict)\n",
    "\n",
    "ee_df.to_csv(\"out-file\")\n",
    "        \n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
